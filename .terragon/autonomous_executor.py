#!/usr/bin/env python3
"""
Autonomous SDLC Executor - Perpetual Value Delivery
Continuously executes highest-value work items with full automation
"""

import asyncio
import json
import subprocess
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import yaml

from value_discovery import ValueDiscoveryEngine, ValueItem

class AutonomousExecutor:
    """Executes value items autonomously with safety checks"""
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)
        self.config_path = self.repo_path / ".terragon" / "config.yaml"
        self.execution_log_path = self.repo_path / ".terragon" / "execution_log.json"
        self.current_work = None
        
        with open(self.config_path) as f:
            self.config = yaml.safe_load(f)
            
        self.execution_history = self._load_execution_history()
    
    def _load_execution_history(self) -> List[Dict]:
        """Load execution history from log file"""
        if self.execution_log_path.exists():
            with open(self.execution_log_path) as f:
                return json.load(f)
        return []
    
    def _save_execution_log(self):
        """Save execution history to log file"""
        with open(self.execution_log_path, "w") as f:
            json.dump(self.execution_history, f, indent=2)
    
    async def execute_value_item(self, item: ValueItem) -> Dict:
        """Execute a single value item with full automation"""
        start_time = time.time()
        execution_record = {
            "item_id": item.id,
            "title": item.title,
            "category": item.category,
            "started_at": datetime.now().isoformat(),
            "estimated_effort": item.effort_estimate,
            "files": item.files,
            "status": "started",
            "changes_made": [],
            "errors": [],
            "rollback_required": False
        }
        
        try:
            print(f"ðŸš€ Executing: {item.title}")
            print(f"   Category: {item.category} | Effort: {item.effort_estimate:.1f}h")
            
            # Create feature branch
            branch_name = f"auto-value/{item.id}-{item.category}"
            await self._create_branch(branch_name)
            execution_record["branch"] = branch_name
            
            # Execute based on category
            if item.category == "security":
                success = await self._execute_security_fix(item, execution_record)
            elif item.category == "automation":
                success = await self._execute_automation_setup(item, execution_record)
            elif item.category == "tooling":
                success = await self._execute_tooling_setup(item, execution_record)
            elif item.category == "code-quality":
                success = await self._execute_code_quality_fix(item, execution_record)
            elif item.category == "technical-debt":
                success = await self._execute_tech_debt_fix(item, execution_record)
            else:
                success = await self._execute_generic_task(item, execution_record)
            
            if success:
                # Run validation tests
                validation_success = await self._validate_changes(execution_record)
                
                if validation_success:
                    # Create pull request
                    pr_url = await self._create_pull_request(item, execution_record)
                    execution_record["pr_url"] = pr_url
                    execution_record["status"] = "completed"
                    
                    print(f"âœ… Completed: {item.title}")
                    print(f"   PR created: {pr_url}")
                else:
                    execution_record["status"] = "validation_failed"
                    execution_record["rollback_required"] = True
                    await self._rollback_changes(execution_record)
            else:
                execution_record["status"] = "execution_failed"
                execution_record["rollback_required"] = True
                await self._rollback_changes(execution_record)
                
        except Exception as e:
            execution_record["status"] = "error"
            execution_record["errors"].append(str(e))
            execution_record["rollback_required"] = True
            await self._rollback_changes(execution_record)
            print(f"âŒ Error executing {item.title}: {e}")
        
        # Record execution metrics
        execution_record["completed_at"] = datetime.now().isoformat()
        execution_record["actual_duration"] = time.time() - start_time
        
        self.execution_history.append(execution_record)
        self._save_execution_log()
        
        return execution_record
    
    async def _create_branch(self, branch_name: str):
        """Create a new git branch for the work"""
        subprocess.run(["git", "checkout", "-b", branch_name], cwd=self.repo_path)
    
    async def _execute_security_fix(self, item: ValueItem, record: Dict) -> bool:
        """Execute security-related fixes"""
        if "requirements.txt" in item.files:
            # Update vulnerable dependencies
            try:
                # Read current requirements
                req_path = self.repo_path / "requirements.txt"
                with open(req_path) as f:
                    requirements = f.read()
                
                # Run safety check to get specific vulnerabilities
                result = subprocess.run([
                    "safety", "check", "--json", "-r", str(req_path)
                ], capture_output=True, text=True)
                
                if result.stdout:
                    vulns = json.loads(result.stdout)
                    
                    # Update vulnerable packages
                    updated_reqs = requirements
                    for vuln in vulns[:3]:  # Fix top 3 vulnerabilities
                        package = vuln.get("package", "")
                        safe_version = vuln.get("safe_version", "")
                        
                        if package and safe_version:
                            # Simple version update (in real implementation, use proper parsing)
                            import re
                            pattern = rf"^{re.escape(package)}==.*$"
                            replacement = f"{package}>={safe_version}"
                            updated_reqs = re.sub(pattern, replacement, updated_reqs, flags=re.MULTILINE)
                    
                    # Write updated requirements
                    with open(req_path, "w") as f:
                        f.write(updated_reqs)
                    
                    record["changes_made"].append(f"Updated vulnerable dependencies in requirements.txt")
                    return True
                    
            except Exception as e:
                record["errors"].append(f"Failed to update dependencies: {e}")
                return False
        
        return True
    
    async def _execute_automation_setup(self, item: ValueItem, record: Dict) -> bool:
        """Execute automation setup tasks"""
        if ".pre-commit-config.yaml" in item.files:
            # Create pre-commit configuration
            precommit_config = """
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-merge-conflict
      
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3.9
        
  - repo: https://github.com/charliermarsh/ruff-pre-commit
    rev: v0.0.270
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
        
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.3.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
"""
            
            config_path = self.repo_path / ".pre-commit-config.yaml"
            with open(config_path, "w") as f:
                f.write(precommit_config.strip())
            
            record["changes_made"].append("Created .pre-commit-config.yaml")
            return True
        
        return True
    
    async def _execute_tooling_setup(self, item: ValueItem, record: Dict) -> bool:
        """Execute tooling setup tasks"""
        if ".editorconfig" in item.files:
            # Create EditorConfig
            editorconfig = """
root = true

[*]
charset = utf-8
end_of_line = lf
indent_style = space
indent_size = 4
insert_final_newline = true
trim_trailing_whitespace = true

[*.{yml,yaml}]
indent_size = 2

[*.{js,json,ts,tsx}]
indent_size = 2

[*.md]
trim_trailing_whitespace = false
"""
            
            config_path = self.repo_path / ".editorconfig"
            with open(config_path, "w") as f:
                f.write(editorconfig.strip())
            
            record["changes_made"].append("Created .editorconfig")
            return True
        
        if ".github/dependabot.yml" in item.files:
            # Create Dependabot configuration
            dependabot_config = """
version: 2
updates:
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
    reviewers:
      - "danieleschmidt"
    assignees:
      - "danieleschmidt"
    open-pull-requests-limit: 5
    
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
    reviewers:
      - "danieleschmidt"
"""
            
            # Create .github directory if it doesn't exist
            github_dir = self.repo_path / ".github"
            github_dir.mkdir(exist_ok=True)
            
            config_path = github_dir / "dependabot.yml"
            with open(config_path, "w") as f:
                f.write(dependabot_config.strip())
            
            record["changes_made"].append("Created .github/dependabot.yml")
            return True
        
        return True
    
    async def _execute_code_quality_fix(self, item: ValueItem, record: Dict) -> bool:
        """Execute code quality fixes"""
        # Run black formatter on affected files
        for file_path in item.files:
            if file_path.endswith('.py'):
                try:
                    subprocess.run([
                        "black", str(self.repo_path / file_path)
                    ], check=True, capture_output=True)
                    
                    record["changes_made"].append(f"Formatted {file_path} with black")
                except subprocess.CalledProcessError:
                    record["errors"].append(f"Failed to format {file_path}")
        
        # Run ruff fixes
        try:
            subprocess.run([
                "ruff", "check", "--fix", str(self.repo_path / "src")
            ], capture_output=True)
            
            record["changes_made"].append("Applied ruff auto-fixes")
        except subprocess.CalledProcessError:
            pass  # Non-critical
        
        return True
    
    async def _execute_tech_debt_fix(self, item: ValueItem, record: Dict) -> bool:
        """Execute technical debt fixes"""
        # For TODO/FIXME items, add a comment indicating it needs manual review
        for file_path in item.files:
            if file_path.endswith('.py'):
                try:
                    file_full_path = self.repo_path / file_path
                    if file_full_path.exists():
                        with open(file_full_path, 'r') as f:
                            content = f.read()
                        
                        # Add a comment indicating this needs review
                        if "TODO" in content or "FIXME" in content:
                            # Add a comment at the top of the file
                            comment = "# NOTE: This file contains technical debt items that need review\n"
                            if not content.startswith(comment):
                                content = comment + content
                                
                                with open(file_full_path, 'w') as f:
                                    f.write(content)
                                
                                record["changes_made"].append(f"Added technical debt review comment to {file_path}")
                        
                except Exception as e:
                    record["errors"].append(f"Failed to process {file_path}: {e}")
        
        return True
    
    async def _execute_generic_task(self, item: ValueItem, record: Dict) -> bool:
        """Execute generic tasks"""
        # For generic tasks, just document them for manual review
        record["changes_made"].append(f"Documented task for manual review: {item.description}")
        return True
    
    async def _validate_changes(self, record: Dict) -> bool:
        """Validate changes by running tests and checks"""
        print("ðŸ” Validating changes...")
        
        # Check if we have any actual changes
        result = subprocess.run([
            "git", "diff", "--name-only"
        ], capture_output=True, text=True, cwd=self.repo_path)
        
        if not result.stdout.strip():
            print("â„¹ï¸  No changes detected")
            return False
        
        # Stage changes
        subprocess.run(["git", "add", "."], cwd=self.repo_path)
        
        # Run basic validation
        validation_steps = [
            # Check Python syntax
            ("python", "-m", "py_compile"),
            # Check with black (dry run)
            ("black", "--check", "--diff", "src/"),
        ]
        
        for step in validation_steps:
            try:
                result = subprocess.run(
                    step, 
                    cwd=self.repo_path, 
                    capture_output=True, 
                    timeout=60
                )
                if result.returncode != 0 and step[1] != "--check":  # black check is allowed to fail
                    record["errors"].append(f"Validation failed: {' '.join(step)}")
                    return False
            except (subprocess.TimeoutExpired, FileNotFoundError):
                continue
        
        print("âœ… Validation passed")
        return True
    
    async def _create_pull_request(self, item: ValueItem, record: Dict) -> str:
        """Create a pull request for the changes"""
        # Commit changes
        commit_msg = f"""[AUTO-VALUE] {item.title}

Category: {item.category}
Estimated Effort: {item.effort_estimate:.1f}h
Value Score: {item.composite_score:.1f}

Changes:
{chr(10).join(f'- {change}' for change in record['changes_made'])}

ðŸ¤– Generated with Terragon Autonomous SDLC

Co-Authored-By: Terragon <noreply@terragon.ai>"""
        
        subprocess.run([
            "git", "commit", "-m", commit_msg
        ], cwd=self.repo_path)
        
        # Push branch (in real implementation, you'd push to remote)
        # subprocess.run(["git", "push", "-u", "origin", record["branch"]], cwd=self.repo_path)
        
        # Return mock PR URL (in real implementation, use GitHub API)
        return f"https://github.com/danieleschmidt/dynamic-graph-fed-rl-lab/pull/{item.id}"
    
    async def _rollback_changes(self, record: Dict):
        """Rollback changes if execution failed"""
        print("ðŸ”„ Rolling back changes...")
        subprocess.run(["git", "reset", "--hard", "HEAD"], cwd=self.repo_path)
        subprocess.run(["git", "checkout", "main"], cwd=self.repo_path)
        subprocess.run(["git", "branch", "-D", record.get("branch", "")], cwd=self.repo_path)

async def run_autonomous_cycle():
    """Run one complete autonomous value discovery and execution cycle"""
    print("ðŸŽ¯ Starting Autonomous SDLC Cycle")
    print("=" * 50)
    
    # Discover value items
    discovery_engine = ValueDiscoveryEngine()
    items = discovery_engine.discover_value_items()
    
    if not items:
        print("â„¹ï¸  No value items discovered")
        return
    
    # Sort by composite score
    items.sort(key=lambda x: x.composite_score, reverse=True)
    
    # Execute top item
    executor = AutonomousExecutor()
    
    # Filter items that haven't been attempted recently
    eligible_items = [item for item in items[:5] if executor._is_eligible_for_execution(item)]
    
    if eligible_items:
        top_item = eligible_items[0]
        print(f"ðŸš€ Executing highest value item: {top_item.title}")
        
        execution_result = await executor.execute_value_item(top_item)
        
        print("ðŸ“Š Execution Summary:")
        print(f"   Status: {execution_result['status']}")
        print(f"   Duration: {execution_result.get('actual_duration', 0):.1f}s")
        print(f"   Changes: {len(execution_result['changes_made'])}")
        
        if execution_result.get('pr_url'):
            print(f"   PR: {execution_result['pr_url']}")
    else:
        print("â„¹ï¸  No eligible items for execution")

class AutonomousExecutor(AutonomousExecutor):
    def _is_eligible_for_execution(self, item: ValueItem) -> bool:
        """Check if item is eligible for execution"""
        # Check if we've attempted this item recently
        recent_attempts = [
            record for record in self.execution_history 
            if record.get('item_id') == item.id and 
            (datetime.now() - datetime.fromisoformat(record.get('started_at', '2020-01-01'))).days < 7
        ]
        
        return len(recent_attempts) == 0

async def main():
    """Main execution loop"""
    await run_autonomous_cycle()

if __name__ == "__main__":
    asyncio.run(main())